{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "E8qV00c1LDvyAj0DhoiP5Z",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {}
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_data = pd.read_csv('/Users/konstantin/MachineLearning/task4/data/train.csv')\n",
    "test_data = pd.read_csv('/Users/konstantin/MachineLearning/task4/data/test.csv')\n",
    "train_data = train_data.drop(columns=[\"Id\"])\n",
    "test_data = test_data.drop(columns=[\"Id\"])\n",
    "for feature in train_data.columns:\n",
    "    percent = train_data[feature].isnull().sum() / train_data.shape[0]\n",
    "    if percent > 0.7:\n",
    "        train_data = train_data.drop(columns=feature)\n",
    "        test_data = test_data.drop(columns=feature)\n",
    "for feature in train_data.columns[:-1]:\n",
    "    if train_data[feature].dtype == 'object':\n",
    "        train_data[feature] = LabelEncoder().fit_transform(train_data[feature])\n",
    "        test_data[feature] = LabelEncoder().fit_transform(test_data[feature])\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data.drop(columns='SalePrice').values,\n",
    "                                                    np.log1p(train_data['SalePrice'].values), test_size=0.2,\n",
    "                                                    random_state=98987)\n",
    "X_train = SimpleImputer(strategy='most_frequent').fit_transform(X_train)\n",
    "X_test = SimpleImputer(strategy='most_frequent').fit_transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train, y_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "VwtxE56zNrnXVybM9YKcyT",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {}
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest Regressor"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "node_id": "Yck1YFbZRt1g7Bd7PZvM8B",
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {}
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "parameters = {\n",
    "    'criterion': ['squared_error', 'absolute_error', 'poisson'],\n",
    "    'n_estimators': [10, 50, 75, 100],\n",
    "    'max_features': [1.0, 'sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 9],\n",
    "    'max_depth': [10, 50, 100, 150], }\n",
    "rfr_model = GridSearchCV(RandomForestRegressor(), parameters)\n",
    "rfr_model.fit(X_train, y_train)\n",
    "print(\"Best parameters for RFR is: {}\".format(rfr_model.best_params_))"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Best parameters for RFR is: {'criterion': 'squared_error', 'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 75}\n"
     ],
     "output_type": "stream"
    }
   ],
   "metadata": {
    "datalore": {
     "node_id": "RHZLhK9ZA1occvtsWFRB0R",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {}
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = RandomForestRegressor(**rfr_model.best_params_)\n",
    "model.fit(X_train, y_train)\n",
    "print('Abs error on train data: %1.2f'%metrics.mean_absolute_error(rfr_model.predict(X_train), y_train))\n",
    "print('Abs error on test data %1.2f:'%metrics.mean_absolute_error(rfr_model.predict(X_test), y_test))"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Abs error on train data: 0.04\n",
      "Abs error on test data 0.11:\n"
     ],
     "output_type": "stream"
    }
   ],
   "metadata": {
    "datalore": {
     "node_id": "UjSoKsalfOHYGNipjVmq7g",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {}
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# XGBoost Regressor"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "node_id": "R8JkFJwkTzu76OD4rTvmLM",
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {}
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Best parameters for XGB is: {'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 300}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    \"learning_rate\": [0.1, 0.2, 0.3],\n",
    "    \"max_depth\": [2, 3, 4, 5, 6],\n",
    "    \"min_child_weight\": [1, 2, 3, 4, 5],\n",
    "    \"n_estimators\": [100, 300, 600, 1000]}\n",
    "xgb_model = GridSearchCV(xgb.XGBRegressor(), parameters)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"Best parameters for XGB is: {}\".format(xgb_model.best_params_))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "xgb_model = xgb.XGBRegressor(**xgb_model.best_params_)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print('Abs error on train data: %1.2f'%metrics.mean_absolute_error(xgb_model.predict(X_train), y_train))\n",
    "print('Abs error on test data %1.2f:'%metrics.mean_absolute_error(xgb_model.predict(X_test), y_test))"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Abs error on train data: 0.04\n",
      "Abs error on test data 0.09:\n"
     ],
     "output_type": "stream"
    }
   ],
   "metadata": {
    "datalore": {
     "node_id": "3HAJ5lDfvjhJOXQBbssEmf",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {}
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python"
  },
  "datalore": {
   "version": 1,
   "computation_mode": "REACTIVE",
   "package_manager": "pip",
   "base_environment": "default",
   "packages": [
    {
     "name": "lightgbm",
     "version": "3.3.3",
     "source": "PIP"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
